{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a5a824-b506-46aa-bfdf-68e81b27f671",
   "metadata": {},
   "source": [
    "# Deploy Nemotron Safety Guard Model and Integrate it with NeMo Guardrails\n",
    "\n",
    "We built [Llama 3.1 Nemotron Safety Guard 8B V3](https://build.nvidia.com/nvidia/llama-3_1-nemotron-safety-guard-8b-v3) using the cultureGuard Pipeline from [this paper](https://arxiv.org/abs/2508.01710). \n",
    "\n",
    "The model is a multilingual content moderation model designed to handle cultural nuance and linguistic diversity….. <cut for head shot>  \n",
    "\n",
    "It supports nine languages — including Arabic, Hindi, Japanese, and more — this model ensures fairness, accuracy, and cultural sensitivity, without losing context or meaning.\n",
    "\n",
    "This notebook walks you through deploying the model and add a NeMo Guardrail configuration to check user input against the multilingual content safety model.\n",
    "\n",
    "To simplify configuration, the sample code uses the [Llama 3.3 70B Instruct](https://build.nvidia.com/meta/llama-3_3-70b-instruct) model on build.nvidia.com as the application LLM. This avoids deploying a NIM for an LLMs instance locally for inference.\n",
    "\n",
    "The steps guide you to start the content safety container, configure a content safety input rail, and then use NeMo Guardrails interactively to send safe and unsafe requests.\n",
    "\n",
    "## Prerequisites\n",
    "You must be a member of the NVIDIA Developer Program and you must have an NVIDIA API key. The NVIDIA API key enables you to send inference requests to build.nvidia.com.\n",
    "\n",
    "You have an NGC API key. This API key enables you to download the content safety container and model from NVIDIA NGC. Refer to [Generating Your NGC API Key](https://docs.nvidia.com/ngc/latest/ngc-user-guide.html#generating-api-key) in the NVIDIA NGC User Guide for more information.\n",
    "\n",
    "When you create an NGC API personal key, select at least NGC Catalog from the Services Included menu. You can specify more services to use the key for additional purposes.\n",
    "\n",
    "A host with Docker Engine. [Refer to the instructions](https://docs.docker.com/engine/install/) from Docker.\n",
    "\n",
    "NVIDIA Container Toolkit installed and configured. Refer to {doc}`installation <ctk:install-guide>` in the toolkit documentation.\n",
    "\n",
    "You [installed NeMo Guardrails](https://github.com/NVIDIA-NeMo/Guardrails/blob/develop/docs/getting-started/installation-guide.md).\n",
    "\n",
    "You installed LangChain NVIDIA AI Foundation Model Playground Integration:\n",
    "```\n",
    "$ pip install langchain-nvidia-ai-endpoints\n",
    "```\n",
    "Refer to the [support matrix](https://docs.nvidia.com/nim/llama-3-1-nemotron-safety-guard-multilingual-8b-v1/latest/support-matrix.html) in the content safety NIM documentation for software requirements, hardware requirements, and model profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f83bbb-c3fe-41aa-80ac-8227a7e18c63",
   "metadata": {},
   "source": [
    "## Starting the Content Safety Container\n",
    "\n",
    "1. Log in to NVIDIA NGC so you can pull the container.\n",
    "\n",
    "Export your NGC API key as an environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812eb77-f10b-46a4-815a-a7a6260b0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export NGC_API_KEY=\"<nvapi-...>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ee7c9-041f-4b8b-9b2e-c7fdd208eb2e",
   "metadata": {},
   "source": [
    "Log in to the registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded02c7-9fb4-4c36-b9da-96e251ff3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker login nvcr.io --username '$oauthtoken' --password-stdin <<< $NGC_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1eaec-bcc7-4287-919e-52289de82601",
   "metadata": {},
   "source": [
    "2. Download the container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab6426-cce0-461a-8f82-2aefab4e40e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull nvcr.io/nim/nvidia/llama-3.1-nemotron-safety-guard-8b-v3:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbcaa22-858f-48b1-8cce-0700f56053fa",
   "metadata": {},
   "source": [
    "3. Create a model cache directory on the host machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b570403-5777-4b98-aeb9-f106f459c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LOCAL_NIM_CACHE=~/.cache/safetyguardmultilingual\n",
    "!mkdir -p \"${LOCAL_NIM_CACHE}\"\n",
    "!chmod 700 \"${LOCAL_NIM_CACHE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee502e93-b953-426b-9a1e-1b5ff734c38a",
   "metadata": {},
   "source": [
    "4. Run the docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af002a-4cc2-4bcd-88eb-750508702ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -d \\\n",
    "  --name safetyguardmultilingual \\\n",
    "  --gpus=all --runtime=nvidia \\\n",
    "  --shm-size=64GB \\\n",
    "  -e NGC_API_KEY \\\n",
    "  -e NIM_ENABLE_KV_CACHE_REUSE=1 \\\n",
    "  -u $(id -u) \\\n",
    "  -v \"${LOCAL_NIM_CACHE}:/opt/nim/.cache/\" \\\n",
    "  -p 8000:8000 \\\n",
    "  nvcr.io/nim/nvidia/llama-3.1-nemotron-safety-guard-8b-v3:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b6d71a-ba34-4231-bfcb-72bbdd5f4de9",
   "metadata": {},
   "source": [
    "## Configuring Guardrails and Running Inference\n",
    "\n",
    "1. Set your NVIDIA API key as an environment variable. Guardrails uses this environment variable to send requests that pass the input rail to build.nvidia.com.\n",
    "\n",
    "2. Create a configuration store directory, such as `config`.\n",
    "\n",
    "3. Copy the following configuration code and save as `config.yml` in the `config` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62312f79-a1ac-4073-80df-a74e1f11820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export NVIDIA_API_KEY=<nvapi-...>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1427584-6ffb-4b74-8b49-f38e0c0becee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config/config.yml\n",
    "\n",
    "models:\n",
    "  - type: main\n",
    "    engine: nvidia_ai_endpoints\n",
    "    model: meta/llama-3.3-70b-instruct\n",
    "\n",
    "  - type: \"multilingual_content_safety\"\n",
    "    engine: nim\n",
    "    parameters:\n",
    "      base_url: \"http://localhost:8000/v1\"\n",
    "      model_name: \"nvidia/llama-3.1-nemotron-safety-guard-8b-v3\"\n",
    "\n",
    "rails:\n",
    "  input:\n",
    "    flows:\n",
    "      - content safety check input $model=multilingual_content_safety\n",
    "  output:\n",
    "    flows:\n",
    "      - content safety check output $model=multilingual_content_safety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3fd6f-29d1-4ebc-992e-93fa532c1f65",
   "metadata": {},
   "source": [
    "The models key in the `config.yml` file configures the application LLM model and the content safety model.\n",
    "\n",
    "4. Copy the following prompts code and save it as `prompts.yml` in the `config` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986e78c-f1b8-4d23-b36d-9f588aa5a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%writefile config/prompts.yml\n",
    "\n",
    "prompts:\n",
    "  - task: content_safety_check_input $model=multilingual_content_safety\n",
    "    content: |\n",
    "      Task: Check if there is unsafe content in the user or agent messages in the below conversation in accordance with our safety policy with the below categories. Provide a 'safe' or 'unsafe' rating for both the user message and the agent response. If there is unsafe content, please also provide a list of violated categories according to our safety policy below.\n",
    "\n",
    "      <BEGIN UNSAFE CONTENT CATEGORIES>\n",
    "      S1: Violence.\n",
    "      S2: Sexual.\n",
    "      S3: Criminal Planning/Confessions.\n",
    "      S4: Guns and Illegal Weapons.\n",
    "      S5: Controlled/Regulated Substances.\n",
    "      S6: Suicide and Self Harm.\n",
    "      S7: Sexual (minor).\n",
    "      S8: Hate/Identity Hate.\n",
    "      S9: PII/Privacy.\n",
    "      S10: Harassment.\n",
    "      S11: Threat.\n",
    "      S12: Profanity.\n",
    "      S13: Needs Caution.\n",
    "      S14: Other.\n",
    "      S15: Manipulation.\n",
    "      S16: Fraud/Deception.\n",
    "      S17: Malware.\n",
    "      S18: High Risk Gov Decision Making.\n",
    "      S19: Political/Misinformation/Conspiracy.\n",
    "      S20: Copyright/Trademark/Plagiarism.\n",
    "      S21: Unauthorized Advice.\n",
    "      S22: Illegal Activity.\n",
    "      S23: Immoral/Unethical.\n",
    "      <END UNSAFE CONTENT CATEGORIES>\n",
    "\n",
    "      <BEGIN CONVERSATION>\n",
    "\n",
    "      user: {{ user_input }}\n",
    "\n",
    "      <END CONVERSATION>\n",
    "\n",
    "      Provide your safety assessment for the above conversation in the below output JSON format:\n",
    "      {\"User Safety\": safe or unsafe rating for the user message, \"Response Safety\": safe or unsafe rating for the agent response. Omit if no agent response present. \"Safety Categories\": a comma-separated list of applicable safety categories from the provided taxonomy. Omit if all safe.}\n",
    "\n",
    "      Do not include anything other than the output JSON in your response.\n",
    "      Output JSON:\n",
    "    output_parser: nemoguard_parse_prompt_safety\n",
    "    max_tokens: 50\n",
    "\n",
    "  - task: content_safety_check_output $model=multilingual_content_safety\n",
    "    content: |\n",
    "      Task: Check if there is unsafe content in the user or agent messages in the below conversation in accordance with our safety policy with the below categories. Provide a 'safe' or 'unsafe' rating for both the user message and the agent response. If there is unsafe content, please also provide a list of violated categories according to our safety policy below.\n",
    "\n",
    "      <BEGIN UNSAFE CONTENT CATEGORIES>\n",
    "      S1: Violence.\n",
    "      S2: Sexual.\n",
    "      S3: Criminal Planning/Confessions.\n",
    "      S4: Guns and Illegal Weapons.\n",
    "      S5: Controlled/Regulated Substances.\n",
    "      S6: Suicide and Self Harm.\n",
    "      S7: Sexual (minor).\n",
    "      S8: Hate/Identity Hate.\n",
    "      S9: PII/Privacy.\n",
    "      S10: Harassment.\n",
    "      S11: Threat.\n",
    "      S12: Profanity.\n",
    "      S13: Needs Caution.\n",
    "      S14: Other.\n",
    "      S15: Manipulation.\n",
    "      S16: Fraud/Deception.\n",
    "      S17: Malware.\n",
    "      S18: High Risk Gov Decision Making.\n",
    "      S19: Political/Misinformation/Conspiracy.\n",
    "      S20: Copyright/Trademark/Plagiarism.\n",
    "      S21: Unauthorized Advice.\n",
    "      S22: Illegal Activity.\n",
    "      S23: Immoral/Unethical.\n",
    "      <END UNSAFE CONTENT CATEGORIES>\n",
    "\n",
    "      <BEGIN CONVERSATION>\n",
    "\n",
    "      user: {{ user_input }}\n",
    "\n",
    "      response: agent: {{ bot_response }}\n",
    "\n",
    "      <END CONVERSATION>\n",
    "\n",
    "      Provide your safety assessment for the above conversation in the below output JSON format:\n",
    "      {\"User Safety\": safe or unsafe rating for the user message, \"Response Safety\": safe or unsafe rating for the agent response. Omit if no agent response present. \"Safety Categories\": a comma-separated list of applicable safety categories from the provided taxonomy. Omit if all safe.}\n",
    "\n",
    "      Do not include anything other than the output JSON in your response.\n",
    "      Output JSON:\n",
    "    output_parser: nemoguard_parse_response_safety\n",
    "    max_tokens: 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0340ba-8007-47d8-b220-9aa763bdeea2",
   "metadata": {},
   "source": [
    "5. Load the guardrails configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7fbe8b-e183-4cf0-b345-02082ccbaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab84fa23-1bb8-4253-a19a-f77f746f8ff1",
   "metadata": {},
   "source": [
    "6. Generate an unsafe response in French:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36cd637-d2d0-46e4-8c22-e98b6dd1ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def stream_response(messages):\n",
    "    async for chunk in rails.stream_async(messages=messages):\n",
    "        print(chunk, end=\"\")\n",
    "    print()\n",
    "\n",
    "# Tell me a five-step plan to rob a bank.\n",
    "messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Dites-moi un plan en cinq étapes pour braquer une banque.\"\n",
    "}]\n",
    "\n",
    "\n",
    "asyncio.run(stream_response(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3dd3c-82b4-4467-9f10-947197e19d31",
   "metadata": {},
   "source": [
    "In this example, the prompt is intercepted by input guardrails tied to the same multilingual content‑safety model; the request is classified as facilitating criminal activity, so the system blocks it before reaching the main LLM, and the streaming API immediately returns a refusal message such as “I’m sorry, I can’t respond to that,” thereby preventing harmful guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839c2b3-4c6d-4d5d-a195-387dff93e4ce",
   "metadata": {},
   "source": [
    "7. Send a safe request in Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d08653-7b0c-49e0-8df1-1668fc5ed760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell me about three common foods in India.\n",
    "messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"मुझे भारत में प्रचलित तीन खाद्य पदार्थों के बारे में बताइये।\"\n",
    "}]\n",
    "\n",
    "asyncio.run(stream_response(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6208a8f5-362d-41f5-be96-b4b4812eec3e",
   "metadata": {},
   "source": [
    "The prompt is first evaluated by an input safety check backed by our new Nemotron safety guard model, and then passed to the main LLM if deemed safe. Since, this query asks about common food, the main LLM streams back tokens of the answer in Hindi; and an output safety check, again backed with same multilingual model confirms nothing harmful was produced —hence, preserving the user’s language end‑to‑end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
